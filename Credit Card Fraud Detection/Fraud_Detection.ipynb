{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud=pd.read_csv('fraud_data.csv')\n",
    "fraud.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are 284807 records, all attributes are numeric, no missing value\n",
    "fraud.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The attributes have very different scales\n",
    "fraud.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obviously, there is a class imbalance problem in the dataset\n",
    "fraud['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class(mean) differ with different Time\n",
    "TH=pd.cut(fraud['Time']/3600, np.arange(0,51,5))\n",
    "grouping = fraud.groupby(TH).mean()\n",
    "grouping['Class'].plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class(mean) differ with different Amount\n",
    "A=pd.cut(fraud['Amount']/1000, np.arange(0,26))\n",
    "grouping = fraud.groupby(A).mean()\n",
    "grouping['Class'].plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=fraud[fraud.columns[:30]]\n",
    "y=fraud[fraud.columns[-1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#As the original dataset is too big that we cannot run it on our computers, we decided to use 10% of the dataset.\n",
    "##We split the dataset half and half as our training set and test set. \n",
    "###train_test_split makse sure that the data is stratified.\n",
    "from sklearn.model_selection import train_test_split\n",
    "a, b, c, d = train_test_split(X, y,random_state = 42, test_size = 0.1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(b, d, random_state = 42, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Scale the data with StandardScaler()\n",
    "scaler=StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use gridsearchCV to find the best parameter for KNeighborsClassifier\n",
    "##It takes a long time to run.\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "grid_values = {'n_neighbors': [2,3,4,5,6,7,8,9,10]}\n",
    "# default metric to optimize over grid parameters: accuracy\n",
    "grid_clf_acc = GridSearchCV(knn, param_grid = grid_values)\n",
    "grid_clf_acc.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "print('Grid best parameter (max. accuracy): ', grid_clf_acc.best_params_)\n",
    "print('Grid best score (accuracy): ', grid_clf_acc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the mean accuracy of validation sets with different n_neighbors\n",
    "score=grid_clf_acc.grid_scores_\n",
    "scores=[x[1] for x in score]\n",
    "\n",
    "n_range=[2,3,4,5,6,7,8,9,10]\n",
    "plt.figure()\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(n_range, scores, color='orange')\n",
    "plt.ylim(0.990,1.001)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try different evaluations on the test set based on the best parameter we got.\n",
    "knnb = KNeighborsClassifier(n_neighbors=5)\n",
    "knnb.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "yp=knnb.predict(X_test_scaled)\n",
    "print('score on test set(accuracy):',accuracy_score(y_test,yp))\n",
    "print('recall:',recall_score(y_test,yp))\n",
    "print('AUC:',roc_auc_score(y_test,yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Did the same for Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression()\n",
    "\n",
    "grid_values = {'C': [0.001, 0.01, 0.05, 0.1, 1, 10, 20]}\n",
    "# default metric to optimize over grid parameters: accuracy\n",
    "grid_clf_acc = GridSearchCV(logit, param_grid = grid_values)\n",
    "grid_clf_acc.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "\n",
    "print('Grid best parameter (max. accuracy): ', grid_clf_acc.best_params_)\n",
    "print('Grid best score (accuracy): ', grid_clf_acc.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=grid_clf_acc.grid_scores_\n",
    "scores=[x[1] for x in score]\n",
    "\n",
    "\n",
    "C_range=[0.001, 0.01, 0.05, 0.1, 1, 10, 20]\n",
    "plt.figure()\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(C_range, scores, color='orange')\n",
    "plt.ylim(0.990,1.001)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logitb=LogisticRegression(C=0.05)\n",
    "logitb.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "yp=logitb.predict(X_test_scaled)\n",
    "print('score on test set(accuracy):',accuracy_score(y_test,yp))\n",
    "print('recall:',recall_score(y_test,yp))\n",
    "print('AUC:',roc_auc_score(y_test,yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The same for SVC linear\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='linear')\n",
    "grid_values = {'C': [0.001, 0.01, 0.05, 0.1, 1, 10]}\n",
    "grid_clf_acc = GridSearchCV(clf, param_grid = grid_values)\n",
    "grid_clf_acc.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "print('Grid best parameter (max. accuracy): ', grid_clf_acc.best_params_)\n",
    "print('Grid best score (accuracy): ', grid_clf_acc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=grid_clf_acc.grid_scores_\n",
    "scores=[x[1] for x in score]\n",
    "\n",
    "C_range=[0.001, 0.01, 0.05, 0.1, 1, 10]\n",
    "plt.figure()\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(C_range, scores, color='orange')\n",
    "plt.ylim(0.991,1.001)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfb= SVC(kernel='linear',C=0.01)\n",
    "clfb.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "yp=clfb.predict(X_test_scaled)\n",
    "print('score on test set(accuracy):',accuracy_score(y_test,yp))\n",
    "print('recall:',recall_score(y_test,yp))\n",
    "print('AUC:',roc_auc_score(y_test,yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The same for SVC rbf\n",
    "clf = SVC(kernel='rbf')\n",
    "grid_values = {'gamma': [0.001, 0.01, 0.05, 0.1, 1, 10]}\n",
    "grid_clf_acc = GridSearchCV(clf, param_grid = grid_values)\n",
    "grid_clf_acc.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "print('Grid best parameter (max. accuracy): ', grid_clf_acc.best_params_)\n",
    "print('Grid best score (accuracy): ', grid_clf_acc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=grid_clf_acc.grid_scores_\n",
    "scores=[x[1] for x in score]\n",
    "\n",
    "gamma_range=[0.001, 0.01, 0.05, 0.1, 1, 10]\n",
    "plt.figure()\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(gamma_range, scores, color='orange')\n",
    "plt.ylim(0.990,1.001)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfb2= SVC(kernel='rbf',gamma=0.001)\n",
    "clfb2.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "yp=clfb2.predict(X_test_scaled)\n",
    "print('score on test set(accuracy):',accuracy_score(y_test,yp))\n",
    "print('recall:',recall_score(y_test,yp))\n",
    "print('AUC:',roc_auc_score(y_test,yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The same for decision tree, but without plotting graph as it will be very difficult\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "grid_values = [\n",
    "{'max_features':[2, 4, 6, 8], 'max_depth': [10,20,30,40,50,60,70,80,90,100] }]\n",
    "# default metric to optimize over grid parameters: accuracy\n",
    "grid_clf_acc = GridSearchCV(tree, param_grid = grid_values)\n",
    "grid_clf_acc.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "print('Grid best parameter (max. accuracy): ', grid_clf_acc.best_params_)\n",
    "print('Grid best score (accuracy): ', grid_clf_acc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeb=DecisionTreeClassifier(random_state=42,max_depth=10,max_features=4)\n",
    "treeb.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "yp=treeb.predict(X_test_scaled)\n",
    "print('score on test set(accuracy):',accuracy_score(y_test,yp))\n",
    "print('recall:',recall_score(y_test,yp))\n",
    "print('AUC:',roc_auc_score(y_test,yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is nothing we can change in naive bayes so we caculated the accuracy/recall/AUC directly.\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nbclf = GaussianNB().fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "nbclf.score(X_test_scaled, y_test.values.reshape(-1))\n",
    "yp= nbclf.predict(X_test_scaled)\n",
    "print('score on test set(accuracy):',accuracy_score(y_test,yp))\n",
    "print('recall:',recall_score(y_test,yp))\n",
    "print('AUC:',roc_auc_score(y_test,yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forests, again we cannot plot the graph.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_values = [\n",
    "{'n_estimators': [5, 10, 20, 30], 'max_features': [2, 4, 6, 8], 'max_depth': [10,20,30,40,50,60,70,80,90,100] }]\n",
    "grid_clf_acc = GridSearchCV(rf, param_grid = grid_values)\n",
    "grid_clf_acc.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "print('Grid best parameter (max. accuracy): ', grid_clf_acc.best_params_)\n",
    "print('Grid best score (accuracy): ', grid_clf_acc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfb=RandomForestClassifier(random_state=42,max_depth=10,max_features=8,n_estimators=5)\n",
    "rfb.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "yp=rfb.predict(X_test_scaled)\n",
    "print('score on test set(accuracy):',accuracy_score(y_test,yp))\n",
    "print('recall:',recall_score(y_test,yp))\n",
    "print('auc:',roc_auc_score(y_test,yp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative metric to optimize over grid parameters: AUC\n",
    "##It takes a long time to run.\n",
    "###We used gridsearchCV to find the best parameter for KNeighborsClassifier using scoring=AUC\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "grid_values = {'n_neighbors': [2,3,4,5,6,7,8,9,10]}\n",
    "# default metric to optimize over grid parameters: accuracy\n",
    "grid_clf_auc = GridSearchCV(knn, param_grid = grid_values, scoring = 'roc_auc')\n",
    "grid_clf_auc.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "print('Grid best parameter (max. AUC): ', grid_clf_auc.best_params_)\n",
    "print('Grid best score (AUC): ', grid_clf_auc.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the mean AUC for validation sets with different n_neighbors\n",
    "score=grid_clf_auc.grid_scores_\n",
    "scores=[x[1] for x in score]\n",
    "\n",
    "n_range=[2,3,4,5,6,7,8,9,10]\n",
    "plt.figure()\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('AUC')\n",
    "plt.scatter(n_range, scores, color='orange')\n",
    "plt.ylim(0.8,1.00)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the best parameter we got and tried the model on test set\n",
    "knnb= KNeighborsClassifier(n_neighbors=4)\n",
    "knnb.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "yp=knnb.predict(X_test_scaled)\n",
    "print('score on test set(AUC):',roc_auc_score(y_test,yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Did the same thing for logit\n",
    "logit = LogisticRegression()\n",
    "\n",
    "grid_values = {'C': [0.001, 0.01, 0.05, 0.1, 1, 10, 20]}\n",
    "# default metric to optimize over grid parameters: accuracy\n",
    "grid_clf_auc = GridSearchCV(logit, param_grid = grid_values, scoring = 'roc_auc')\n",
    "grid_clf_auc.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "print('Grid best parameter (max. AUC): ', grid_clf_auc.best_params_)\n",
    "print('Grid best score (AUC): ', grid_clf_auc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=grid_clf_auc.grid_scores_\n",
    "scores=[x[1] for x in score]\n",
    "\n",
    "\n",
    "C_range=[0.001, 0.01, 0.05, 0.1, 1, 10, 20]\n",
    "plt.figure()\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('AUC')\n",
    "plt.scatter(C_range, scores, color='orange')\n",
    "plt.ylim(0.90,1.001)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logitb= LogisticRegression(C=0.01)\n",
    "logitb.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "yp=logitb.predict(X_test_scaled)\n",
    "print('score on test set(AUC):',roc_auc_score(y_test,yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same for SVC linear\n",
    "clf = SVC(kernel='linear')\n",
    "grid_values = {'C': [0.001, 0.01, 0.05, 0.1, 1, 10]}\n",
    "grid_clf_auc = GridSearchCV(clf, param_grid = grid_values, scoring = 'roc_auc')\n",
    "grid_clf_auc.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "print('Grid best parameter (max. AUC): ', grid_clf_auc.best_params_)\n",
    "print('Grid best score (AUC): ', grid_clf_auc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=grid_clf_auc.grid_scores_\n",
    "scores=[x[1] for x in score]\n",
    "\n",
    "C_range=[0.001, 0.01, 0.05, 0.1, 1, 10]\n",
    "plt.figure()\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('AUC')\n",
    "plt.scatter(C_range, scores, color='orange')\n",
    "plt.ylim(0.85,1.001)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfb=SVC(kernel='linear', C= 0.1)\n",
    "clfb.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "yp=clfb.predict(X_test_scaled)\n",
    "print('score on test set(AUC):',roc_auc_score(y_test,yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same thing for SVC rbf\n",
    "clf = SVC(kernel='rbf')\n",
    "grid_values = {'gamma': [0.001, 0.01, 0.05, 0.1, 1, 10]}\n",
    "grid_clf_auc = GridSearchCV(clf, param_grid = grid_values, scoring = 'roc_auc')\n",
    "grid_clf_auc.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "print('Grid best parameter (max. AUC): ', grid_clf_auc.best_params_)\n",
    "print('Grid best score (AUC): ', grid_clf_auc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=grid_clf_auc.grid_scores_\n",
    "scores=[x[1] for x in score]\n",
    "\n",
    "gamma_range=[0.001, 0.01, 0.05, 0.1, 1, 10]\n",
    "plt.figure()\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('AUC')\n",
    "plt.scatter(gamma_range, scores, color='orange')\n",
    "plt.ylim(0.7,1.001)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfb2=SVC(kernel='rbf', gamma= 0.1)\n",
    "clfb2.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "yp=clfb2.predict(X_test_scaled)\n",
    "print('score on test set(AUC):',roc_auc_score(y_test,yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same on DecisionTreeClassifier, without plotting graph\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "grid_values = [\n",
    "{'max_features':[2, 4, 6, 8], 'max_depth': [10,20,30,40,50,60,70,80,90,100] }]\n",
    "# default metric to optimize over grid parameters: accuracy\n",
    "grid_clf_auc = GridSearchCV(tree, param_grid = grid_values, scoring = 'roc_auc')\n",
    "grid_clf_auc.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "print('Grid best parameter (max.AUC): ', grid_clf_auc.best_params_)\n",
    "print('Grid best score (AUC): ', grid_clf_auc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeb=DecisionTreeClassifier(random_state=42,max_depth=10,max_features=8)\n",
    "treeb.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "yp=treeb.predict(X_test_scaled)\n",
    "print('score on test set(AUC):',roc_auc_score(y_test,yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same for RandomForestClassifier, without plotting graph\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_values = [\n",
    "{'n_estimators': [5, 10, 20, 30], 'max_features': [2, 4, 6, 8], 'max_depth': [10,20,30,40,50,60,70,80,90,100] }]\n",
    "grid_clf_auc = GridSearchCV(rf, param_grid = grid_values, scoring = 'roc_auc')\n",
    "grid_clf_auc.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "print('Grid best parameter (max.AUC): ', grid_clf_auc.best_params_)\n",
    "print('Grid best score (AUC): ', grid_clf_auc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfb = RandomForestClassifier(random_state=42, max_depth=20,max_features=2, n_estimators= 20)\n",
    "rfb.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "yp=rfb.predict(X_test_scaled)\n",
    "print('score on test set(AUC):',roc_auc_score(y_test,yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Negative class (0) is most frequent\n",
    "dummy_majority = DummyClassifier(strategy = 'most_frequent').fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "# Therefore the dummy 'most_frequent' classifier always predicts class 0\n",
    "y_dummy_predictions = dummy_majority.predict(X_test_scaled)\n",
    "print('score on test set(accuracy):',accuracy_score(y_test,y_dummy_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We prefer AUC rather than recall, so this part is just for our reference\n",
    "##You may skip this part as it will take extra long time to run\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "grid_values = {'n_neighbors': [2,3,4,5,6,7,8,9,10]}\n",
    "# default metric to optimize over grid parameters: accuracy\n",
    "grid_clf_recall = GridSearchCV(knn, param_grid = grid_values, scoring = 'recall')\n",
    "grid_clf_recall.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "print('Grid best parameter (max. recall): ', grid_clf_recall.best_params_)\n",
    "print('Grid best score (recall): ', grid_clf_recall.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnb= KNeighborsClassifier(n_neighbors=3)\n",
    "knnb.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "yp=knnb.predict(X_test_scaled)\n",
    "print('score on test set(recall):',recall_score(y_test,yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()\n",
    "\n",
    "grid_values = {'C': [0.001, 0.01, 0.05, 0.1, 1, 10, 20]}\n",
    "# default metric to optimize over grid parameters: accuracy\n",
    "grid_clf_recall = GridSearchCV(logit, param_grid = grid_values, scoring = 'recall')\n",
    "grid_clf_recall.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "print('Grid best parameter (max. recall): ', grid_clf_recall.best_params_)\n",
    "print('Grid best score (recall): ', grid_clf_recall.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logitb= LogisticRegression(C=10)\n",
    "logitb.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "yp=logitb.predict(X_test_scaled)\n",
    "print('score on test set(recall):',recall_score(y_test,yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='linear')\n",
    "grid_values = {'C': [0.001, 0.01, 0.05, 0.1, 1, 10]}\n",
    "grid_clf_recall = GridSearchCV(clf, param_grid = grid_values, scoring = 'recall')\n",
    "grid_clf_recall.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "print('Grid best parameter (max. recall): ', grid_clf_recall.best_params_)\n",
    "print('Grid best score (recall): ', grid_clf_recall.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfb=SVC(kernel='linear', C= 0.01)\n",
    "clfb.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "yp=clfb.predict(X_test_scaled)\n",
    "print('score on test set(recall):',recall_score(y_test,yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf')\n",
    "grid_values = {'gamma': [0.001, 0.01, 0.05, 0.1, 1, 10]}\n",
    "grid_clf_recall = GridSearchCV(clf, param_grid = grid_values, scoring = 'recall')\n",
    "grid_clf_recall.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "print('Grid best parameter (max. recall): ', grid_clf_recall.best_params_)\n",
    "print('Grid best score (recall): ', grid_clf_recall.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfb=SVC(kernel='rbf', gamma= 0.001)\n",
    "clfb.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "yp=clfb.predict(X_test_scaled)\n",
    "print('score on test set(recall):',recall_score(y_test,yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "grid_values = [\n",
    "{'max_features':[2, 4, 6, 8], 'max_depth': [10,20,30,40,50,60,70,80,90,100] }]\n",
    "grid_clf_recall = GridSearchCV(tree, param_grid = grid_values, scoring = 'recall')\n",
    "grid_clf_recall.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "print('Grid best parameter (max. recall): ', grid_clf_recall.best_params_)\n",
    "print('Grid best score (recall): ', grid_clf_recall.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeb=DecisionTreeClassifier(random_state=42,max_depth=10,max_features=8)\n",
    "treeb.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "yp=treeb.predict(X_test_scaled)\n",
    "print('score on test set(recall):',recall_score(y_test,yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_values = [\n",
    "{'n_estimators': [5, 10, 20, 30], 'max_features': [2, 4, 6, 8], 'max_depth': [10,20,30,40,50,60,70,80,90,100] }]\n",
    "grid_clf_recall = GridSearchCV(rf, param_grid = grid_values, scoring = 'recall')\n",
    "grid_clf_recall.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "print('Grid best parameter (max. recall): ', grid_clf_recall.best_params_)\n",
    "print('Grid best score (recall): ', grid_clf_recall.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfb = RandomForestClassifier(random_state=42, max_depth=10,max_features=8, n_estimators= 5)\n",
    "rfb.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "yp=rfb.predict(X_test_scaled)\n",
    "print('score on test set(recall):',recall_score(y_test,yp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We picked some models that performed well on the first part and used ensemble, bagging and pasting to improve the classification accuracy. \n",
    "logit_clf=LogisticRegression(C=0.05,random_state=42)\n",
    "rnd_clf=RandomForestClassifier(max_depth=10, max_features=8, n_estimators=5,random_state=42)\n",
    "svm_clf=SVC(kernel='rbf',gamma=0.001,probability=True, random_state=42)\n",
    "knn_clf=KNeighborsClassifier(n_neighbors=5)\n",
    "tree_clf=DecisionTreeClassifier(max_depth=10, max_features=4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used hard voting ensemble method\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('logit',logit_clf), ('rf',rnd_clf), ('svc',svm_clf),('knn',knn_clf)], voting='hard')\n",
    "voting_clf.fit(X_train_scaled, y_train.values.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy increased a little bit\n",
    "for clf in (logit_clf, rnd_clf, svm_clf, knn_clf,voting_clf):\n",
    "    clf.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "    yp=clf.predict(X_test_scaled)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test.values.reshape(-1), yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applied bagging to different models, the accuracies improved a little bit.\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "for clf in (logit_clf, svm_clf, knn_clf):\n",
    "    bag_clf = BaggingClassifier(clf, bootstrap=True, random_state=42)\n",
    "    bag_clf.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "    yp=bag_clf .predict(X_test_scaled)\n",
    "    print('With Bagging:',clf.__class__.__name__,'accuracy score:', accuracy_score(y_test.values.reshape(-1), yp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applied pasting to different models, only the accuracy of SVC increased, others' the same.\n",
    "for clf in (logit_clf, svm_clf, knn_clf):\n",
    "    bag_clf = BaggingClassifier(clf, bootstrap=False, random_state=42)\n",
    "    bag_clf.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "    yp=bag_clf .predict(X_test_scaled)\n",
    "    print('With Pasting:',clf.__class__.__name__,'accuracy score:', accuracy_score(y_test.values.reshape(-1), yp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tried AdaBoostClassifier and GradientBoosting. We cannot furthur improve the accuracy.\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "for clf in (logit_clf, rnd_clf,tree_clf):\n",
    "    ada_clf = AdaBoostClassifier(clf,learning_rate=0.5, random_state=42)\n",
    "    ada_clf.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "    yp=ada_clf .predict(X_test_scaled)\n",
    "    print('With Adaboost:',clf.__class__.__name__,'accuracy score:', accuracy_score(y_test.values.reshape(-1), yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "Grb_clf = GradientBoostingClassifier(learning_rate=0.5, random_state=42)\n",
    "Grb_clf.fit(X_train_scaled, y_train.values.reshape(-1))\n",
    "yp=Grb_clf .predict(X_test_scaled)\n",
    "print('accuracy score:', accuracy_score(y_test.values.reshape(-1), yp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Applied dimension reduction on several models \n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.85)\n",
    "X_train_reduced=pca.fit_transform(X_train_scaled)\n",
    "X_test_reduced=pca.fit_transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The accuracy increased but AUC and recall dropped dramatically\n",
    "for clf in (logit_clf, rnd_clf, svm_clf, knn_clf, voting_clf):\n",
    "    clf.fit(X_train_reduced, y_train.values.reshape(-1))\n",
    "    yp=clf.predict(X_test_reduced)\n",
    "    print(clf.__class__.__name__, 'accuracy:', accuracy_score(y_test.values.reshape(-1), yp))\n",
    "    print(clf.__class__.__name__, 'recall:', recall_score(y_test.values.reshape(-1), yp))\n",
    "    print(clf.__class__.__name__, 'AUC:', roc_auc_score(y_test.values.reshape(-1), yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
